{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import zarr\n",
    "import gcsfs\n",
    "from tqdm.autonotebook import tqdm\n",
    "import os\n",
    "import cftime\n",
    "import json\n",
    "from dask import array\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_kubernetes import KubeCluster\n",
    "\n",
    "cluster = KubeCluster()\n",
    "cluster.adapt(minimum=1, maximum=20, interval='2s')\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')\n",
    "gcs = gcsfs.GCSFileSystem(token='anon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_csv('pangeo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_srch_data(df, source_id, expt_id):\n",
    "\n",
    "    uri = df[(df.source_id == source_id) &\n",
    "                         (df.experiment_id == expt_id)].zstore.values[0]\n",
    "    \n",
    "    ds = xr.open_zarr(gcs.get_mapper(uri), consolidated=True)\n",
    "    return ds\n",
    "\n",
    "def load_data(series):\n",
    "    ds = xr.open_zarr(gcs.get_mapper(series.zstore), consolidated=True)\n",
    "    return ds\n",
    "\n",
    "def get_dims(ds):\n",
    "    ds_coords = [l for l in list(ds.coords.keys()) if 'bnds' not in l and 'vert' not in l]\n",
    "    dims = [[l for l in ds_coords if 'lat' in l][0], [l for l in ds_coords if 'lon' in l][0]]\n",
    "    lat = ds.coords.get(dims[0])\n",
    "    lon = ds.coords.get(dims[1])\n",
    "    return lat, lon, dims\n",
    "\n",
    "def get_area(ds, df):\n",
    "    var = ds.get(ds.variable_id)\n",
    "    realm = ds.table_id[0].lower()\n",
    "    lat, lon, dims = get_dims(ds)\n",
    "\n",
    "    df_area = df.query(\"variable_id == 'areacell\"+realm+\"' & source_id == '\"+ds.source_id+\"' & grid_label== '\"+ds.grid_label+\"'\")\n",
    "    if len(df_area.zstore.values) == 0:\n",
    "        if len(lat.data) > 2000:\n",
    "            area = np.cos(lat * np.pi / 180)\n",
    "            dims = [\"ncells\"]\n",
    "            total_area = lat.sum()\n",
    "        elif np.shape(lat) == np.shape(var)[1:]:\n",
    "            area = np.cos(lat.data * np.pi / 180)\n",
    "            total_area = area.sum()\n",
    "            dims = ds.get(dims[0]).dims\n",
    "        else:\n",
    "            time, area, lon = np.meshgrid(ds.time, np.cos(lat.data * np.pi / 180), lon, indexing='ij')\n",
    "            total_area = area[0,:,:].sum()\n",
    "    else:\n",
    "        ds_area = xr.open_zarr(gcs.get_mapper(df_area.zstore.values[0]), consolidated=True)\n",
    "        area = ds_area.get(\"areacell\"+realm)\n",
    "        total_area = area.sum(area.dims)\n",
    "        dims = area.dims\n",
    "\n",
    "    return area, dims, total_area\n",
    "\n",
    "def avg_var(ds, df):\n",
    "    area, dims, total_area = get_area(ds, df)\n",
    "    var = ds.get(ds.variable_id)\n",
    "    \n",
    "    ta_timeseries = (var * area).sum(dim=dims) / total_area\n",
    "    \n",
    "    if isinstance(ta_timeseries, type(None)):\n",
    "        print('failed')\n",
    "    return ta_timeseries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all files available on Pangeo servers\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in tqdm(list(range(len(dfs)))):\n",
    "    s = dfs.iloc[num]\n",
    "    name = '_'.join([s.source_id, s.experiment_id, s.member_id, s.variable_id])\n",
    "    \n",
    "    ds = load_data(s)\n",
    "    df_area = df.query(\"variable_id == 'areacell\"+ds.table_id[0].lower()+\"' & source_id == '\"+ds.source_id+\"' & grid_label== '\"+ds.grid_label+\"'\")\n",
    "    if len(df_area.zstore.values != 0):\n",
    "        continue\n",
    "        \n",
    "    print(str(num)+\" : \"+name)\n",
    "\n",
    "    if ds.experiment_id == 'piControl' or ds.experiment_id == '1pctCO2':\n",
    "        ds = ds.sel(time=slice(ds.time[0], ds.time[min([1799, len(ds.time)-1])]))\n",
    "    elif len(ds.time) > 2400:\n",
    "        ds = ds.sel(time=slice(ds.time[0], ds.time[2399]))\n",
    "    m = avg_var(ds, df)\n",
    "\n",
    "    if not isinstance(m, type(None)):\n",
    "        np.save('data/'+name, np.array([m.values[:], np.array([np.datetime64(t) for t in m.time.values])[:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all files not available on Pangeo's servers\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "manual = json.load(open('manual_loads.txt','r'))\n",
    "allfiles = json.load(open('allfiles.txt','r'))\n",
    "mapping = defaultdict(list)\n",
    "[mapping['_'.join([a.split('/')[9],a.split('/')[11],a.split('/')[10]]+ a.split('/')[12:14])].append(a) for a in allfiles]\n",
    "to_load = [(m, mapping.get(m)) for m in manual]\n",
    "to_load = sorted(to_load, key=lambda x: len(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all info I need to download these by hand.\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = pd.read_csv('saved-data.csv')\n",
    "failed = []\n",
    "esgf = pd.DataFrame([m.split('_') for m in manual])\n",
    "esgf = esgf.rename(columns={0:'source_id',1:'member_id',2:'experiment_id',3:'table_id',4:'variable_id'})\n",
    "esgf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge downloaded mlotst files\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('wgets/abrupt-4xCO2-mlotst')\n",
    "files = pd.DataFrame([m.replace('.nc','').split('_') + [m] for m in files])\n",
    "files = files.rename(columns={0:\"variable_id\",1:\"table_id\",2:\"source_id\",3:\"experiment_id\",4:\"member_id\",5:\"grid_label\",6:\"time_range\",7:\"file_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "failed = []\n",
    "for key, group in files.groupby(['experiment_id','variable_id','source_id','member_id']):\n",
    "    group = group.sort_values(by=['time_range'])\n",
    "    \n",
    "    merged = None\n",
    "    t = False\n",
    "    \n",
    "    try:\n",
    "        for f in group['file_name']:\n",
    "                ds = xr.open_dataset('wgets/abrupt-4xCO2-mlotst/'+f)\n",
    "                m = avg_var(ds, df)\n",
    "                if not t:\n",
    "                    merged = m\n",
    "                else:\n",
    "                    merged = xr.concat([merged, m],\"time\")\n",
    "\n",
    "        if not isinstance(merged, type(None)):\n",
    "            series = group.iloc[0]\n",
    "            fname = '_'.join([series.source_id, series.experiment_id, series.member_id, series.variable_id])\n",
    "            saved = pd.concat([saved, group])\n",
    "            np.save('manual_data/'+fname, np.array([m.values[:], np.array([np.datetime64(t) for t in m.time.values])[:]]))\n",
    "    except OSError:\n",
    "        print(\"failed on\",f)\n",
    "        failed.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyesgf.search import SearchConnection\n",
    "conn = SearchConnection('http://esgf-data.lnll.gov/esg-search', distrib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-32f9bc276c4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvariant_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r1i1p1f2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     data_node='esgf-data3.ceda.ac.uk')\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhit_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyesgf/search/context.py\u001b[0m in \u001b[0;36mhit_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhit_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__hit_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyesgf/search/context.py\u001b[0m in \u001b[0;36m__update_counts\u001b[0;34m(self, ignore_facet_check)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mquery_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'facets'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfacets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         for facet, counts in (response['facet_counts']['facet_fields']\n\u001b[1;32m    209\u001b[0m                               .items()):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyesgf/search/connection.py\u001b[0m in \u001b[0;36msend_search\u001b[0;34m(self, query_dict, limit, offset, shards)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'search'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "ctx = conn.new_context(\n",
    "    project='CMIP6',\n",
    "    source_id='UKESM1-0-LL',\n",
    "    experiment_id='historical',\n",
    "    variable='tas',\n",
    "    frequency='mon',\n",
    "    variant_label='r1i1p1f2',\n",
    "    data_node='esgf-data3.ceda.ac.uk')\n",
    "ctx.hit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
