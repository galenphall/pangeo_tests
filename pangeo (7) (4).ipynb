{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import zarr\n",
    "import gcsfs\n",
    "from tqdm.autonotebook import tqdm\n",
    "import os\n",
    "import cftime\n",
    "import json\n",
    "from dask import array\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:  tcp://10.48.160.10:45299\n",
      "distributed.scheduler - INFO -   dashboard at:                     :8787\n",
      "distributed.scheduler - INFO - Receive client connection: Client-388d421a-6df1-11ea-81d9-0a2b65f2e791\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.48.160.10:45299</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/ghall3-pangeo_tests-65pk03ig/proxy/8787/status' target='_blank'>/user/ghall3-pangeo_tests-65pk03ig/proxy/8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.48.160.10:45299' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_kubernetes import KubeCluster\n",
    "\n",
    "cluster = KubeCluster()\n",
    "cluster.adapt(minimum=1, maximum=20, interval='2s')\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>zstore</th>\n",
       "      <th>dcpp_init_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>histSST</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>AERmon</td>\n",
       "      <td>mmrbc</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>histSST</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>AERmon</td>\n",
       "      <td>mmrdust</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>histSST</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>AERmon</td>\n",
       "      <td>mmroa</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>histSST</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>AERmon</td>\n",
       "      <td>mmrso4</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>histSST</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>AERmon</td>\n",
       "      <td>mmrss</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  activity_id institution_id source_id experiment_id member_id table_id  \\\n",
       "0  AerChemMIP            BCC  BCC-ESM1       histSST  r1i1p1f1   AERmon   \n",
       "1  AerChemMIP            BCC  BCC-ESM1       histSST  r1i1p1f1   AERmon   \n",
       "2  AerChemMIP            BCC  BCC-ESM1       histSST  r1i1p1f1   AERmon   \n",
       "3  AerChemMIP            BCC  BCC-ESM1       histSST  r1i1p1f1   AERmon   \n",
       "4  AerChemMIP            BCC  BCC-ESM1       histSST  r1i1p1f1   AERmon   \n",
       "\n",
       "  variable_id grid_label                                             zstore  \\\n",
       "0       mmrbc         gn  gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...   \n",
       "1     mmrdust         gn  gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...   \n",
       "2       mmroa         gn  gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...   \n",
       "3      mmrso4         gn  gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...   \n",
       "4       mmrss         gn  gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...   \n",
       "\n",
       "   dcpp_init_year  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')\n",
    "gcs = gcsfs.GCSFileSystem(token='anon')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_csv('pangeo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_attrs = json.load(open('file_attrs.txt','r'))\n",
    "# all_attrs = set(['_'.join([a['source_id'],a['member_id'],a['experiment_id'],a['table_id'],a['variable_id']]) for a in file_attrs])\n",
    "\n",
    "# def want(s, m, e, t, v):\n",
    "#     key = s+'_'+m+'_'+e+'_'+t+'_'+v\n",
    "#     return s+'_'+m+'_'+e+'_'+t+'_'+v\n",
    "\n",
    "# dfs = df[df[['source_id','member_id','experiment_id','table_id','variable_id']].apply(lambda x: want(*x) in all_attrs, axis=1)]\n",
    "\n",
    "# pangeo_attrs = set(dfs[['source_id','member_id','experiment_id','table_id','variable_id']].apply(lambda x: want(*x), axis=1).values)\n",
    "# manual_attrs = [a for a in all_attrs if a not in pangeo_attrs]\n",
    "# json.dump(list(pangeo_attrs), open('pangeo_loads.txt', 'w'))\n",
    "# json.dump(list(manual_attrs), open('manual_loads.txt', 'w'))\n",
    "\n",
    "# dfs.to_csv('pangeo_loads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_srch_data(df, source_id, expt_id):\n",
    "\n",
    "    uri = df[(df.source_id == source_id) &\n",
    "                         (df.experiment_id == expt_id)].zstore.values[0]\n",
    "    \n",
    "    ds = xr.open_zarr(gcs.get_mapper(uri), consolidated=True)\n",
    "    return ds\n",
    "\n",
    "def load_data(series):\n",
    "    ds = xr.open_zarr(gcs.get_mapper(series.zstore), consolidated=True)\n",
    "    return ds\n",
    "\n",
    "def get_dims(ds):\n",
    "    ds_coords = [l for l in list(ds.coords.keys()) if 'bnds' not in l and 'vert' not in l]\n",
    "    dims = [[l for l in ds_coords if 'lat' in l][0], [l for l in ds_coords if 'lon' in l][0]]\n",
    "    lon = ds.coords.get(dims[0])\n",
    "    lat = ds.coords.get(dims[1])\n",
    "    return lat, lon\n",
    "\n",
    "def get_area(ds, df):\n",
    "    var = ds.get(ds.variable_id)\n",
    "    realm = ds.table_id[0].lower()\n",
    "    area = None\n",
    "    lat, lon = get_dims(ds)\n",
    "    dims = [lat.name, lon.name]\n",
    "\n",
    "    df_area = df.query(\"variable_id == 'areacell\"+realm+\"' & source_id == '\"+ds.source_id+\"'\")\n",
    "    if len(df_area.zstore.values) == 0:\n",
    "        if len(lat) > 1000:\n",
    "            area = lat\n",
    "            dims = [\"ncells\"]\n",
    "            total_area = lat.sum()\n",
    "        time, lon, area = np.meshgrid(ds.time, lon, np.cos(lat), indexing='ij')\n",
    "        total_area = area[0,:,:].sum()\n",
    "    else:\n",
    "        ds_area = xr.open_zarr(gcs.get_mapper(df_area.zstore.values[0]), consolidated=True)\n",
    "        area = ds_area.get(\"areacell\"+realm)\n",
    "        total_area = area.sum(dims)\n",
    "\n",
    "    return area, dims, total_area\n",
    "\n",
    "def avg_var(ds, df):\n",
    "    area, dims, total_area = get_area(ds, df)\n",
    "    var = ds.get(ds.variable_id)\n",
    "    \n",
    "    ta_timeseries = (var * area).sum(dim=dims) / total_area\n",
    "    \n",
    "    if isinstance(ta_timeseries, type(None)):\n",
    "        print('failed')\n",
    "    return ta_timeseries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba76c515a86487a875975fdbd697cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=431.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353 : GISS-E2-1-G_piControl_r1i1p1f3_ts\n",
      "356 : GISS-E2-1-G_piControl_r2i1p1f1_ts\n",
      "359 : GISS-E2-2-G_1pctCO2_r1i1p1f1_ts\n",
      "361 : GISS-E2-2-G_piControl_r1i1p1f1_ts\n",
      "364 : CESM2-FV2_piControl_r1i1p1f1_ts\n",
      "369 : CESM2-WACCM-FV2_piControl_r1i1p1f1_ts\n",
      "374 : CESM2-WACCM_1pctCO2_r1i1p1f1_ts\n",
      "377 : CESM2-WACCM_abrupt-4xCO2_r1i1p1f1_ts\n",
      "380 : CESM2-WACCM_piControl_r1i1p1f1_ts\n",
      "385 : CESM2_1pctCO2_r1i1p1f1_ts\n",
      "388 : CESM2_abrupt-4xCO2_r1i1p1f1_ts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.48.161.38:42049', name: 3, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.48.161.38:42049\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 : CESM2_piControl_r1i1p1f1_ts\n",
      "396 : NorCPM1_1pctCO2_r1i1p1f1_ts\n",
      "399 : NorCPM1_abrupt-4xCO2_r1i1p1f1_ts\n",
      "401 : NorCPM1_piControl_r1i1p1f1_ts\n",
      "402 : NorCPM1_piControl_r2i1p1f1_ts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Retire worker names (0,)\n",
      "distributed.scheduler - INFO - Retire workers {<Worker 'tcp://10.48.161.32:42461', name: 0, memory: 3, processing: 0>}\n",
      "distributed.scheduler - INFO - Moving 3 keys to other workers\n",
      "distributed.scheduler - INFO - Closing worker tcp://10.48.161.32:42461\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.48.161.32:42461', name: 0, memory: 3, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.48.161.32:42461\n",
      "distributed.deploy.adaptive - INFO - Retiring workers [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403 : NorCPM1_piControl_r3i1p1f1_ts\n",
      "404 : NorESM2-LM_abrupt-4xCO2_r1i1p1f1_ts\n",
      "405 : NorESM2-MM_1pctCO2_r1i1p1f1_ts\n",
      "406 : NorESM2-MM_abrupt-4xCO2_r1i1p1f1_ts\n",
      "407 : GFDL-CM4_piControl_r1i1p1f1_ts\n",
      "411 : GFDL-ESM4_piControl_r1i1p1f1_ts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.48.161.39:32819', name: 4, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.48.161.39:32819\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416 : NESM3_1pctCO2_r1i1p1f1_rlut\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Retire worker names (4,)\n",
      "distributed.scheduler - INFO - Retire workers {<Worker 'tcp://10.48.161.39:32819', name: 4, memory: 0, processing: 1>}\n",
      "distributed.scheduler - INFO - Closing worker tcp://10.48.161.39:32819\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.48.161.39:32819', name: 4, memory: 0, processing: 1>\n",
      "distributed.core - INFO - Removing comms to tcp://10.48.161.39:32819\n",
      "distributed.deploy.adaptive - INFO - Retiring workers [4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417 : NESM3_1pctCO2_r1i1p1f1_rsdt\n",
      "418 : NESM3_1pctCO2_r1i1p1f1_rsut\n",
      "419 : NESM3_1pctCO2_r1i1p1f1_ts\n",
      "422 : NESM3_abrupt-4xCO2_r1i1p1f1_rlut\n",
      "423 : NESM3_abrupt-4xCO2_r1i1p1f1_rsdt\n",
      "424 : NESM3_abrupt-4xCO2_r1i1p1f1_rsut\n",
      "425 : NESM3_abrupt-4xCO2_r1i1p1f1_ts\n",
      "428 : NESM3_piControl_r1i1p1f1_ts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/xarray/coding/times.py:426: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/numpy/core/_asarray.py:85: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for num in tqdm(list(range(len(dfs)))):\n",
    "    s = dfs.iloc[num]\n",
    "    name = '_'.join([s.source_id, s.experiment_id, s.member_id, s.variable_id])\n",
    "    if name in below_avg[:,0]:\n",
    "        ds = load_data(s)\n",
    "        break\n",
    "    \n",
    "    if s.table_id == 'Omon' or name + '.npy' in os.listdir('data') or 'EC-Earth3' in s.source_id:\n",
    "        continue\n",
    "        \n",
    "    print(str(num),':',name)\n",
    "    \n",
    "    ds = load_data(s)\n",
    "    if ds.experiment_id == 'piControl' or ds.experiment_id == '1pctCO2':\n",
    "        ds = ds.sel(time=slice(ds.time[0], ds.time[min([1799, len(ds.time)-1])]))\n",
    "    elif len(ds.time) > 2400:\n",
    "        ds = ds.sel(time=slice(ds.time[0], ds.time[2399]))\n",
    "    m = avg_var(ds, df)\n",
    "\n",
    "    if not isinstance(m, type(None)):\n",
    "        np.save('data/'+name, np.array([m.values[:], np.array([np.datetime64(t) for t in m.time.values])[:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.array([[f, np.load('data/'+f, allow_pickle = True)] for f in os.listdir('data') if \"1pctCO2\" in f and '_ts.npy' in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MPI-ESM1-2-HR_1pctCO2_r1i1p1f1_ts.npy',\n",
       "       'MPI-ESM1-2-LR_1pctCO2_r1i1p1f1_ts.npy',\n",
       "       'NorCPM1_1pctCO2_r1i1p1f1_ts.npy'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "below_avg = np.array([n for n in ns if np.mean(n[1][0]) < 200])\n",
    "below_avg[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-7168839aca5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbelow_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "plt.figure(\"1pctCO2 runs\")\n",
    "for f, n in ns:\n",
    "    if not isinstance(n[1,0], type(int)) and f not in below_avg[:,0]:\n",
    "        w = 30\n",
    "        plt.plot_date(pd.to_datetime(n[1,int(w/2):len(n)-1-w/2)]), moving_average(n[0], w), xdate=True, fmt='-k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = int(30)\n",
    "int(w/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = []\n",
    "lons = []\n",
    "for r in tqdm(range(len(dfs))):\n",
    "    ds = load_data(dfs.iloc[r])\n",
    "    ds_coords = [l for l in list(ds.coords.keys()) if 'bnds' not in l and 'vert' not in l]\n",
    "    lat_key = [l for l in ds_coords if 'lat' in l]\n",
    "    lon_key = [l for l in ds_coords if 'lon' in l]\n",
    "    lats += [lat_key]\n",
    "    lons += [lon_key]\n",
    "print(set(lats))\n",
    "print(set(lons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentiles(ds, df):\n",
    "    Area = get_area(ds, df)\n",
    "    Var = ds.get(ds.variable_id)\n",
    "    \n",
    "    percentiles = []\n",
    "    \n",
    "    for t in range(len(Var.time)):\n",
    "        area = Area[t]\n",
    "        var = Var[t]\n",
    "        time = Var.time[t]\n",
    "        \n",
    "        weights = np.reshape(area.data, (np.prod(np.shape(var)),1))\n",
    "        vals = np.reshape(var.data, (np.prod(np.shape(var)),1))\n",
    "        weights = np.array(weights[~np.isnan(vals)])\n",
    "        vals = np.array(vals[~np.isnan(vals)])\n",
    "\n",
    "        idx = np.argsort(vals)\n",
    "        vals = np.take_along_axis(vals, idx, axis=0)\n",
    "        sorted_weights = np.array(np.take_along_axis(weights, idx, axis=0))\n",
    "        total = np.nansum(weights)\n",
    "\n",
    "        i = 0\n",
    "        low = 0\n",
    "        N = len(weights)\n",
    "        pcts = np.array([0.05, 0.17, 0.5, 0.83, 0.95])\n",
    "        pct_vals = []\n",
    "        for j in range(0,len(vals)):\n",
    "            low = low + sorted_weights[j]\n",
    "            high = low + sorted_weights[min(j+1,N)]\n",
    "            # If the cumulative weights are nearest the next percentile\n",
    "            # Then mark down the value\n",
    "            if low/total < pcts[i] and high/total >= pcts[i]:\n",
    "                pct_vals += [[pcts[i], vals[j]]]\n",
    "                if i == np.shape(pcts)[0] - 1:\n",
    "                    break\n",
    "                i = i + 1\n",
    "                \n",
    "        percentiles += [time, pct_vals]\n",
    "    \n",
    "    return percentiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
