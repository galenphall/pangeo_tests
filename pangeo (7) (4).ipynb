{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/ipykernel_launcher.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import zarr\n",
    "import gcsfs\n",
    "from tqdm.autonotebook import tqdm\n",
    "import os\n",
    "import cftime\n",
    "import json\n",
    "from dask import array\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_kubernetes import KubeCluster\n",
    "\n",
    "cluster = KubeCluster()\n",
    "cluster.adapt(minimum=1, maximum=20, interval='2s')\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')\n",
    "gcs = gcsfs.GCSFileSystem(token='anon')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_csv('pangeo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_attrs = json.load(open('file_attrs.txt','r'))\n",
    "# all_attrs = set(['_'.join([a['source_id'],a['member_id'],a['experiment_id'],a['table_id'],a['variable_id']]) for a in file_attrs])\n",
    "\n",
    "# def want(s, m, e, t, v):\n",
    "#     key = s+'_'+m+'_'+e+'_'+t+'_'+v\n",
    "#     return s+'_'+m+'_'+e+'_'+t+'_'+v\n",
    "\n",
    "# dfs = df[df[['source_id','member_id','experiment_id','table_id','variable_id']].apply(lambda x: want(*x) in all_attrs, axis=1)]\n",
    "\n",
    "# pangeo_attrs = set(dfs[['source_id','member_id','experiment_id','table_id','variable_id']].apply(lambda x: want(*x), axis=1).values)\n",
    "# manual_attrs = [a for a in all_attrs if a not in pangeo_attrs]\n",
    "# json.dump(list(pangeo_attrs), open('pangeo_loads.txt', 'w'))\n",
    "# json.dump(list(manual_attrs), open('manual_loads.txt', 'w'))\n",
    "\n",
    "# dfs.to_csv('pangeo_loads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_srch_data(df, source_id, expt_id):\n",
    "\n",
    "    uri = df[(df.source_id == source_id) &\n",
    "                         (df.experiment_id == expt_id)].zstore.values[0]\n",
    "    \n",
    "    ds = xr.open_zarr(gcs.get_mapper(uri), consolidated=True)\n",
    "    return ds\n",
    "\n",
    "def load_data(series):\n",
    "    ds = xr.open_zarr(gcs.get_mapper(series.zstore), consolidated=True)\n",
    "    return ds\n",
    "\n",
    "def get_dims(ds):\n",
    "    ds_coords = [l for l in list(ds.coords.keys()) if 'bnds' not in l and 'vert' not in l]\n",
    "    dims = [[l for l in ds_coords if 'lat' in l][0], [l for l in ds_coords if 'lon' in l][0]]\n",
    "    lon = ds.coords.get(dims[0])\n",
    "    lat = ds.coords.get(dims[1])\n",
    "    return lat, lon\n",
    "\n",
    "def get_area(ds, df):\n",
    "    var = ds.get(ds.variable_id)\n",
    "    realm = ds.table_id[0].lower()\n",
    "    lat, lon = get_dims(ds)\n",
    "\n",
    "    df_area = df.query(\"variable_id == 'areacell\"+realm+\"' & source_id == '\"+ds.source_id+\"'\")\n",
    "    if len(df_area.zstore.values) == 0:\n",
    "        if len(lat) > 1000:\n",
    "            area = lat\n",
    "            dims = [\"ncells\"]\n",
    "            total_area = lat.sum()\n",
    "        time, lon, area = np.meshgrid(ds.time, lon, np.cos(lat), indexing='ij')\n",
    "        total_area = area[0,:,:].sum()\n",
    "    else:\n",
    "        ds_area = xr.open_zarr(gcs.get_mapper(df_area.zstore.values[0]), consolidated=True)\n",
    "        area = ds_area.get(\"areacell\"+realm)\n",
    "        total_area = area.sum([lat.name, lon.name])\n",
    "\n",
    "    return area, [lat.name, lon.name], total_area\n",
    "\n",
    "def avg_var(ds, df):\n",
    "    area, dims, total_area = get_area(ds, df)\n",
    "    var = ds.get(ds.variable_id)\n",
    "    \n",
    "    ta_timeseries = (var * area).sum(dim=[d.name for d in dims]) / total_area\n",
    "    \n",
    "    if isinstance(ta_timeseries, type(None)):\n",
    "        print('failed')\n",
    "    return ta_timeseries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in tqdm(list(range(len(dfs)))):\n",
    "    s = dfs.iloc[num]\n",
    "    name = '_'.join([s.source_id, s.experiment_id, s.member_id, s.variable_id])\n",
    "    if name in below_avg[:,0]:\n",
    "        ds = load_data(s)\n",
    "        break\n",
    "    \n",
    "    if s.table_id == 'Amon' or name + '.npy' in os.listdir('data') or 'EC-Earth3' in s.source_id:\n",
    "        continue\n",
    "        \n",
    "    print(str(num),':',name)\n",
    "    \n",
    "    ds = load_data(s)\n",
    "    if ds.experiment_id == 'piControl' or ds.experiment_id == '1pctCO2':\n",
    "        ds = ds.sel(time=slice(ds.time[0], ds.time[min([1799, len(ds.time)-1])]))\n",
    "    elif len(ds.time) > 2400:\n",
    "        ds = ds.sel(time=slice(ds.time[0], ds.time[2399]))\n",
    "    m = avg_var(ds, df)\n",
    "\n",
    "    if not isinstance(m, type(None)):\n",
    "        np.save('data/'+name, np.array([m.values[:], np.array([np.datetime64(t) for t in m.time.values])[:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 30-year moving average $\\Delta T$  for 1pctCO2 runs\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.array([[f, np.load('data/'+f, allow_pickle = True)] for f in os.listdir('data') if \"1pctCO2\" in f and '_ts.npy' in f])\n",
    "below_ts = np.array([n for n in ns if np.mean(n[1][0]) < 200])\n",
    "dates = [pd.to_datetime(n[1], errors='coerce') for n in ns[:,1]][0]\n",
    "plt.figure(\"1pctCO2 runs\")\n",
    "for f, n in ns:\n",
    "    if not isinstance(n[1,0], type(int)) and f not in below_ts[:,0]:\n",
    "        w = 30\n",
    "        plt.plot_date(dates[int(w/2)-1:int(len(n[0])-w/2)],\n",
    "                      moving_average(n[0], w),\n",
    "                      xdate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 30-year moving average $\\Delta T$  for abrupt-4x runs\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.array([[f, np.load('data/'+f, allow_pickle = True)] for f in os.listdir('data') if \"abrupt\" in f and '_ts.npy' in f])\n",
    "below_ts = np.array([n[0] for n in ns if np.mean(n[1][0]) < 200])\n",
    "short_ts = np.array([n[0] for n in ns if len(n[1][1]) < 1700])\n",
    "dates = [d for d in [pd.to_datetime(n[1], errors='coerce') for n in ns[:,1]] if d[0] != 'NaT']\n",
    "plt.figure(\"1pctCO2 runs\")\n",
    "for f, n in ns:\n",
    "    if f not in below_ts and f not in short_ts:\n",
    "        w = 30\n",
    "        d = next(d for d in dates if len(d) == len(n[0]))\n",
    "        plt.plot_date(d[int(w/2)-1:int(len(n[0])-w/2)],\n",
    "                      moving_average(n[0], w),\n",
    "                      xdate=True, fmt='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(dates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentiles(ds, df):\n",
    "    Area = get_area(ds, df)\n",
    "    Var = ds.get(ds.variable_id)\n",
    "    \n",
    "    percentiles = []\n",
    "    \n",
    "    for t in range(len(Var.time)):\n",
    "        area = Area[t]\n",
    "        var = Var[t]\n",
    "        time = Var.time[t]\n",
    "        \n",
    "        weights = np.reshape(area.data, (np.prod(np.shape(var)),1))\n",
    "        vals = np.reshape(var.data, (np.prod(np.shape(var)),1))\n",
    "        weights = np.array(weights[~np.isnan(vals)])\n",
    "        vals = np.array(vals[~np.isnan(vals)])\n",
    "\n",
    "        idx = np.argsort(vals)\n",
    "        vals = np.take_along_axis(vals, idx, axis=0)\n",
    "        sorted_weights = np.array(np.take_along_axis(weights, idx, axis=0))\n",
    "        total = np.nansum(weights)\n",
    "\n",
    "        i = 0\n",
    "        low = 0\n",
    "        N = len(weights)\n",
    "        pcts = np.array([0.05, 0.17, 0.5, 0.83, 0.95])\n",
    "        pct_vals = []\n",
    "        for j in range(0,len(vals)):\n",
    "            low = low + sorted_weights[j]\n",
    "            high = low + sorted_weights[min(j+1,N)]\n",
    "            # If the cumulative weights are nearest the next percentile\n",
    "            # Then mark down the value\n",
    "            if low/total < pcts[i] and high/total >= pcts[i]:\n",
    "                pct_vals += [[pcts[i], vals[j]]]\n",
    "                if i == np.shape(pcts)[0] - 1:\n",
    "                    break\n",
    "                i = i + 1\n",
    "                \n",
    "        percentiles += [time, pct_vals]\n",
    "    \n",
    "    return percentiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dims(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
